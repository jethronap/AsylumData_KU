{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex as re\n",
    "import utilities.helpers as hp\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import NMF, TruncatedSVD, LatentDirichletAllocation\n",
    "\n",
    "from tmtoolkit.topicmod.evaluate import metric_coherence_gensim\n",
    "\n",
    "import pyLDAvis.sklearn\n",
    "\n",
    "plt.style.use(style='seaborn')\n",
    "%matplotlib inline\n",
    "sns.set()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALL cases topic modelling: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "df_full = hp.import_dataset(encoding='utf-8')\n",
    "df_full.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset preprocessing:\n",
    "\n",
    "All cases except for Unknown Homeland (Ukendt hjemland) are kept.\n",
    "\n",
    "Below we see the shape and head of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_UH = df_full[df_full.country != \"Ukendt hjemland\"]\n",
    "\n",
    "# Drop redundant column:\n",
    "df_UH.drop('hasText', axis=1, inplace=True)\n",
    "\n",
    "# Keep column 'text':\n",
    "df = df_UH[['text']]\n",
    "\n",
    "df[\"text\"] = df[\"text\"].astype(str)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for potential duplicates and drop them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates_df = df[df.duplicated(['text'], keep=False)]\n",
    "#pd.concat(g for _, g in df.groupby(\"text\") if len(g) > 1)\n",
    "\n",
    "# See all duplicates:\n",
    "duplicates_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New shape for dataset after droping duplicate entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates from original dataframe:\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Check shape again:\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use a pipeline to pre-process the texts:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline consists of the following steps:\n",
    "\n",
    "- Lowercase all characters\n",
    "- Drop numbers\n",
    "- Remove punctuation\n",
    "- Remove stopwords. The list of stopwords can be found [here](https://github.com/jethronap/AsylumData_KU/blob/main/misc/stopwords_dk.txt).\n",
    "- Single letter words are dropped, too.\n",
    "- Tokenization\n",
    "- Lemmatization. The process during which all words are turned into its roots. \n",
    "\n",
    "Steps can be added or removed from the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = [str.lower, hp.drop_numbers, hp.remove_punctuation, hp.remove_stopwords, hp.drop_single_letter_words,\n",
    "            hp.tokenize, hp.lemmatize]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the process pipeline:\n",
    "df['tokens'] = df['text'].apply(hp.process, pipeline=pipeline)\n",
    "\n",
    "# Add column to see the number of tokens:\n",
    "df['num_tokens'] = df['tokens'].map(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens_joined'] = [' '.join(token) for token in df['tokens']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use tf (raw term count) features for LDA.\n",
    "count_text_vectorizer = CountVectorizer(min_df=2, max_df=0.7)\n",
    "count_text_vectors = count_text_vectorizer.fit_transform(df['tokens_joined'])\n",
    "\n",
    "# Use tf-idf features for NMF and SVD\n",
    "tfidf_text_vectorizer = TfidfVectorizer(min_df=2, max_df=0.7)\n",
    "tfidf_text_vectors = tfidf_text_vectorizer.fit_transform(df['tokens_joined'])\n",
    "# tfidf_text_vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modelling:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Dirichlet Allocation (LDA):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "best_num_LDA = float('NaN')\n",
    "best_score_LDA = 0\n",
    "\n",
    "# Compute the coherence scores for each number of topics\n",
    "for i in range(2, 11):\n",
    "\n",
    "    # Create LDA model with i topics\n",
    "    LDA_text_model = LatentDirichletAllocation(n_components=i, random_state=42)\n",
    "    W_LDA_text_matrix = LDA_text_model.fit_transform(count_text_vectors)\n",
    "    H_LDA_text_matrix = LDA_text_model.components_\n",
    "\n",
    "    # Obtain the coherence score\n",
    "    coherence_model_LDA = metric_coherence_gensim(measure='c_v', \n",
    "                        top_n=25, \n",
    "                        topic_word_distrib=H_LDA_text_matrix, \n",
    "                        dtm=W_LDA_text_matrix, \n",
    "                        vocab=np.array([x for x in count_text_vectorizer.vocabulary_.keys()]), \n",
    "                        texts=df['tokens'])\n",
    "    coherence_score_LDA = np.around(coherence_model_LDA, 2)\n",
    "    for score in coherence_score_LDA:\n",
    "        if score > best_score_LDA:\n",
    "            best_num_LDA = i\n",
    "            best_score_LDA = score\n",
    "\n",
    "print(f'The coherence score for LDA ({best_score_LDA}) is highest with {best_num_LDA} topics.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the model with the best number of topics and see them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA_model = LatentDirichletAllocation(n_components=best_num_LDA, random_state=42)\n",
    "W_LDA_model_matrix = LDA_model.fit_transform(count_text_vectors)\n",
    "H_LDA_model_matrix = LDA_model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.display_topics(LDA_model, count_text_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise the topics produced by LDA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "LDA_display = pyLDAvis.sklearn.prepare(LDA_model, count_text_vectors, count_text_vectorizer, sort_topics=False)\n",
    "\n",
    "pyLDAvis.display(LDA_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.save_html(LDA_display, 'LDA_ALL.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each bubble in the plot represents a topic. The size of the bubble represents the proportion of cases that contain the topic, with a larger bubble corresponding to a higher proportion. \n",
    "\n",
    "The distance between the bubbles represents the similarity between the topics; the shorter the distance, the more similar the topics.\n",
    "\n",
    "The bars in the bar chart represent the term frequency for each of the words. The blue bars show the overall term frequency in the collection of documents, whereas the red bars show the term frequency for the selected topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Negative Matrix Factorization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "best_num_NMF = float('NaN')\n",
    "best_score_NMF = 0\n",
    "\n",
    "# Compute the coherence scores for each number of topics\n",
    "for i in range(2, 11):\n",
    "\n",
    "    # Create NMF model with i topics\n",
    "    NMF_text_model = NMF(n_components=i, random_state=42, max_iter=2000)\n",
    "    W_NMF_text_matrix = NMF_text_model.fit_transform(tfidf_text_vectors)\n",
    "    H_NMF_text_matrix = NMF_text_model.components_\n",
    "\n",
    "    # Obtain the coherence score\n",
    "    coherence_model_NMF = metric_coherence_gensim(measure='c_v', \n",
    "                        top_n=25, \n",
    "                        topic_word_distrib=H_NMF_text_matrix, \n",
    "                        dtm=W_NMF_text_matrix, \n",
    "                        vocab=np.array([x for x in tfidf_text_vectorizer.vocabulary_.keys()]), \n",
    "                        texts=df['tokens'])\n",
    "    coherence_score_NMF = np.around(coherence_model_NMF, 2)\n",
    "    for score in coherence_score_NMF:\n",
    "        if score > best_score_NMF:\n",
    "            best_num_NMF = i\n",
    "            best_score_NMF = score\n",
    "\n",
    "print(f'The coherence score for NMF ({best_score_NMF}) is highest with {best_num_NMF} topics.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the model with the best number of topics and see them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NMF_model = NMF(n_components=best_num_NMF, random_state=42, max_iter=2000)\n",
    "W_NMF_model_matrix = NMF_model.fit_transform(tfidf_text_vectors)\n",
    "H_NMF_model_matrix = NMF_model.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numbers inside the parentheses are the percentages with which the words contribute to the topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.display_topics(NMF_model, count_text_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise the topics produced by NMF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "\n",
    "NMF_display = pyLDAvis.sklearn.prepare(NMF_model, tfidf_text_vectors, tfidf_text_vectorizer, sort_topics=False)\n",
    "\n",
    "pyLDAvis.display(NMF_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.save_html(NMF_display, 'NMF_ALL.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Semantic Analysis/Indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "best_num_SVD = float('NaN')\n",
    "best_score_SVD = 0\n",
    "\n",
    "# Compute the coherence scores for each number of topics\n",
    "for i in range(2, 11):\n",
    "\n",
    "    # Create SVD model with i topics\n",
    "    SVD_text_model = TruncatedSVD(n_components=i, random_state=42)\n",
    "    W_SVD_text_matrix = SVD_text_model.fit_transform(tfidf_text_vectors)\n",
    "    H_SVD_text_matrix = SVD_text_model.components_\n",
    "\n",
    "    # Obtain the coherence score\n",
    "    coherence_model_SVD = metric_coherence_gensim(measure='c_v', \n",
    "                        top_n=25, \n",
    "                        topic_word_distrib=H_SVD_text_matrix, \n",
    "                        dtm=W_SVD_text_matrix, \n",
    "                        vocab=np.array([x for x in tfidf_text_vectorizer.vocabulary_.keys()]), \n",
    "                        texts=df['tokens'])\n",
    "    coherence_score_SVD = np.around(coherence_model_SVD, 2)\n",
    "    for score in coherence_score_SVD:\n",
    "        if score > best_score_SVD:\n",
    "            best_num_SVD = i\n",
    "            best_score_SVD = score\n",
    "\n",
    "print(f'The coherence score for SVD ({best_score_SVD}) is highest with {best_num_SVD} topics.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the model with the best number of topics and see them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVD_model = TruncatedSVD(n_components=best_num_SVD, random_state=42)\n",
    "W_SVD_model_matrix = SVD_model.fit_transform(tfidf_text_vectors)\n",
    "H_SVD_model_matrix = SVD_model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.display_topics(SVD_model, tfidf_text_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVD_display = pyLDAvis.sklearn.prepare(SVD_model, tfidf_text_vectors, tfidf_text_vectorizer, sort_topics=False)\n",
    "\n",
    "# pyLDAvis.display(SVD_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wordclouds:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WordClouds from the LDA model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.wordcloud_topics(LDA_model, count_text_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WordClouds from the NMF model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.wordcloud_topics(NMF_model, tfidf_text_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WordsClouds from the SVD model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.wordcloud_topics(SVD_model, tfidf_text_vectorizer.get_feature_names_out())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b6672ba510bd43d5df0d34395a84685a825e41d35f5301d8abef98bca1680e82"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
