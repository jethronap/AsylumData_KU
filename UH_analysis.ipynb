{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jnap/opt/anaconda3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/jnap/opt/anaconda3/lib/python3.9/site-packages/matplotlib_inline/config.py:66: DeprecationWarning: InlineBackend._figure_formats_changed is deprecated in traitlets 4.1: use @observe and @unobserve instead.\n",
      "  def _figure_formats_changed(self, name, old, new):\n",
      "/Users/jnap/opt/anaconda3/lib/python3.9/site-packages/seaborn/rcmod.py:400: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(mpl.__version__) >= \"3.0\":\n",
      "/Users/jnap/opt/anaconda3/lib/python3.9/site-packages/setuptools/_distutils/version.py:351: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import regex as re\n",
    "import pprint\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "# Need to uncomment the following line in order to download nltk stopwords:\n",
    "# nltk.download('stopwords')\n",
    "import spacy\n",
    "from textacy.extract import keyword_in_context\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.decomposition import NMF, TruncatedSVD, LatentDirichletAllocation\n",
    "\n",
    "from collections import defaultdict\n",
    "from collections import Counter, ChainMap\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from tmtoolkit.topicmod.evaluate import metric_coherence_gensim\n",
    "\n",
    "import pyLDAvis.sklearn\n",
    "\n",
    "plt.style.use(style='seaborn')\n",
    "%matplotlib inline\n",
    "sns.set()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9324, 5)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "with open('data/dk_asylum_data.json', encoding='utf-8') as inputfile:\n",
    "    df_full = pd.read_json(inputfile)\n",
    "\n",
    "# Convert json to csv:\n",
    "df_full.to_csv('data/dk_asylum_data.csv', encoding='utf-8', index=False)\n",
    "\n",
    "df_full.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset preprocessing:\n",
    "\n",
    "## Keep cases of Unknown Homeland (Ukendt hjemland):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_UH = df_full[df_full.country == \"Ukendt hjemland\"]\n",
    "\n",
    "# Drop redundant column:\n",
    "df_UH.drop('hasText', axis=1, inplace=True)\n",
    "\n",
    "# Keep column 'text':\n",
    "df = df_UH[['text']]\n",
    "\n",
    "df[\"text\"] = df[\"text\"].astype(str)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>Nævnet stadfæstede i november 2021 Udl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>Nævnet stadfæstede i juni 2021 Udlændi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>Nævnet stadfæstede i juni 2021 Udlændi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>Nævnet stadfæstede i december 2020 Udl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>Nævnet hjemviste i juni 2020 Udlænding...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "201           Nævnet stadfæstede i november 2021 Udl...\n",
       "428           Nævnet stadfæstede i juni 2021 Udlændi...\n",
       "464           Nævnet stadfæstede i juni 2021 Udlændi...\n",
       "901           Nævnet stadfæstede i december 2020 Udl...\n",
       "1291          Nævnet hjemviste i juni 2020 Udlænding..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for potential duplicates and drop them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>Nævnet stadfæstede i maj 2020 Udlændin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>Nævnet stadfæstede i maj 2020 Udlændin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000</th>\n",
       "      <td>Nævnet stadfæstede i januar 2018 Udlæn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4001</th>\n",
       "      <td>Nævnet stadfæstede i januar 2018 Udlæn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4055</th>\n",
       "      <td>Nævnet stadfæstede i januar 2018 Udlæn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4058</th>\n",
       "      <td>Nævnet stadfæstede i januar 2018 Udlæn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "1333          Nævnet stadfæstede i maj 2020 Udlændin...\n",
       "1352          Nævnet stadfæstede i maj 2020 Udlændin...\n",
       "4000          Nævnet stadfæstede i januar 2018 Udlæn...\n",
       "4001          Nævnet stadfæstede i januar 2018 Udlæn...\n",
       "4055          Nævnet stadfæstede i januar 2018 Udlæn...\n",
       "4058          Nævnet stadfæstede i januar 2018 Udlæn..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates_df = df[df.duplicated(['text'], keep=False)]\n",
    "#pd.concat(g for _, g in df.groupby(\"text\") if len(g) > 1)\n",
    "\n",
    "# See all duplicates:\n",
    "duplicates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(189, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop duplicates from original dataframe:\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Check shape again:\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Length of texts\n",
    "\n",
    "Create a numeric column in order to get a feel about the length of the texts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>length</th>\n",
       "      <td>189.0</td>\n",
       "      <td>5008.539683</td>\n",
       "      <td>2046.292952</td>\n",
       "      <td>1104.0</td>\n",
       "      <td>3532.0</td>\n",
       "      <td>4753.0</td>\n",
       "      <td>6057.0</td>\n",
       "      <td>13105.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count         mean          std     min     25%     50%     75%  \\\n",
       "length  189.0  5008.539683  2046.292952  1104.0  3532.0  4753.0  6057.0   \n",
       "\n",
       "            max  \n",
       "length  13105.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['length'] = df['text'].str.len()\n",
    "\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Box plot:\n",
    "df['length'].plot(kind='box', vert=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histogram:\n",
    "df['length'].plot(kind='hist', bins=30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a pipeline:\n",
    "\n",
    "Below are the steps taken to process the texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load danish model from spacy:\n",
    "nlp = spacy.load(\"da_core_news_md\")\n",
    "\n",
    "STOPWORDS_DANISH = set(stopwords.words('danish'))\n",
    "\n",
    "# domain specific words included:\n",
    "domain_stopwords = {'nævnet', 'januar', 'februar', 'marts', 'april',\n",
    "'maj', 'juni', 'juli', 'august', 'september', 'oktober', 'november', 'december', 'jf', 'ansøger'}\n",
    "\n",
    "def import_additional_danish_stopwords(STOPWORDS_DANISH):\n",
    "    additional_stopwords = open('stopwords_dk.txt', 'r')\n",
    "    for line in additional_stopwords:\n",
    "        words = line.strip()\n",
    "        STOPWORDS_DANISH.add(words)\n",
    "    return STOPWORDS_DANISH\n",
    "\n",
    "\n",
    "STOPWORDS_DANISH = import_additional_danish_stopwords(STOPWORDS_DANISH)\n",
    "STOPWORDS_DANISH |= domain_stopwords \n",
    "\n",
    "PUNCTUATION_TO_REMOVE = '–«!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~»●·’“”'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(STOPWORDS_DANISH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    \"\"\"custom function to remove the punctuation\"\"\"\n",
    "    return text.translate(str.maketrans('', '', PUNCTUATION_TO_REMOVE))\n",
    "\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    \"\"\"custom function to remove stopwords\"\"\"\n",
    "    return [word for word in str(text).split() if word not in STOPWORDS_DANISH] \n",
    "    # [t for t in text if t not in STOPWORDS_DANISH]\n",
    "\n",
    "\n",
    "# def tokenize(text):\n",
    "#     \"\"\"the following expression matches tokens consisting of at least one letter (\\p{L}), \n",
    "#     preceded and followed by an arbitrary sequence of alphanumeric characters \n",
    "#     (\\w includes digits, letters, and underscore) and hyphens (-)\"\"\"\n",
    "#     return re.findall(r'[\\w-]*\\p{L}[\\w-]*', text)\n",
    "\n",
    "def tokenize(text):\n",
    "    doc = nlp.tokenizer(' '.join(text))\n",
    "    return [token.text for token in doc]\n",
    "\n",
    "def drop_single_letter_words(text):\n",
    "    return [w for w in text if len(w) > 1]\n",
    "\n",
    "\n",
    "def lemmatize(text):\n",
    "    \"\"\"custom function to lemmatize text\"\"\"\n",
    "    doc = nlp(' '.join(text))\n",
    "    # pos_tagged_text = text.pos\n",
    "    return [token.lemma_ for token in doc]\n",
    "\n",
    "# def remove_junk(text):\n",
    "#     # Creating a spacy object\n",
    "#     doc = nlp(' '.join(text))\n",
    "#     # Checking if POS tag is X and printing them\n",
    "#     for token in doc:\n",
    "#         if token.pos_ == 'X':\n",
    "#             print(token.text)\n",
    "#     # Removing the tokens whose POS tag is junk.\n",
    "#     clean_doc = [token.text for token in doc if not token.pos_ == 'X']\n",
    "\n",
    "#     return clean_doc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps can be added or removed from the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = [str.lower, remove_punctuation, remove_stopwords, drop_single_letter_words,\n",
    "            tokenize, lemmatize]\n",
    "\n",
    "\n",
    "def process(text, pipeline):\n",
    "    tokens = text\n",
    "    for transform in pipeline:\n",
    "        tokens = transform(tokens)\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the process pipeline:\n",
    "df['tokens'] = df['text'].apply(process, pipeline=pipeline)\n",
    "\n",
    "# Add column to see the number of tokens:\n",
    "df['num_tokens'] = df['tokens'].map(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>tokens</th>\n",
       "      <th>num_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>Nævnet stadfæstede i november 2021 Udl...</td>\n",
       "      <td>4753</td>\n",
       "      <td>[stadfæste, 2021, udlændingestyrels, afgørelse...</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>Nævnet stadfæstede i juni 2021 Udlændi...</td>\n",
       "      <td>3149</td>\n",
       "      <td>[stadfæste, 2021, udlændingestyrels, afgørelse...</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>Nævnet stadfæstede i juni 2021 Udlændi...</td>\n",
       "      <td>4433</td>\n",
       "      <td>[stadfæste, 2021, udlændingestyrels, afgørelse...</td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>Nævnet stadfæstede i december 2020 Udl...</td>\n",
       "      <td>2664</td>\n",
       "      <td>[stadfæste, 2020, udlændingestyrels, afgørelse...</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>Nævnet hjemviste i juni 2020 Udlænding...</td>\n",
       "      <td>4626</td>\n",
       "      <td>[hjemvise, 2020, udlændingestyrels, afgørelse,...</td>\n",
       "      <td>332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  length  \\\n",
       "201           Nævnet stadfæstede i november 2021 Udl...    4753   \n",
       "428           Nævnet stadfæstede i juni 2021 Udlændi...    3149   \n",
       "464           Nævnet stadfæstede i juni 2021 Udlændi...    4433   \n",
       "901           Nævnet stadfæstede i december 2020 Udl...    2664   \n",
       "1291          Nævnet hjemviste i juni 2020 Udlænding...    4626   \n",
       "\n",
       "                                                 tokens  num_tokens  \n",
       "201   [stadfæste, 2021, udlændingestyrels, afgørelse...         342  \n",
       "428   [stadfæste, 2021, udlændingestyrels, afgørelse...         232  \n",
       "464   [stadfæste, 2021, udlændingestyrels, afgørelse...         329  \n",
       "901   [stadfæste, 2020, udlændingestyrels, afgørelse...         192  \n",
       "1291  [hjemvise, 2020, udlændingestyrels, afgørelse,...         332  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantitative analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens_joined'] = [' '.join(token) for token in df['tokens']]\n",
    "\n",
    "df_stad = df['tokens_joined'].str.contains('stadfæste', regex=True)\n",
    "df_hem = df['tokens_joined'].str.contains('hjemvise', regex=True)\n",
    "df_med = df['tokens_joined'].str.contains('meddele', regex=True)\n",
    "\n",
    "# df['decision'] = np.where(df_stad & (df_hem | df_med), \"check\", np.nan)\n",
    "df['decision'] = np.where((df_hem | df_med) & df_stad, \"denied\", np.where(\n",
    "    df_hem | df_med, \"granted\", np.where(df_stad, \"denied\", np.nan)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot decision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'outcomes')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = ['blue', 'orange']\n",
    "\n",
    "# Plot with normalized values:\n",
    "ax = df['decision'].value_counts(normalize=True).mul(100).round(1).plot(\n",
    "    kind='barh', color=colors, title='Decision Outcomes for Unknown Homeland')\n",
    "\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fmt='%.0f%%')\n",
    "ax.set_xlabel('% of outcomes')\n",
    "ax.set_ylabel('outcomes')\n",
    "\n",
    "# Uncomment to plot frequencies:\n",
    "# ax = df['decision'].value_counts().plot(\n",
    "#     kind='barh', color=colors, title='Decision Outcomes for Unknown Homeland')\n",
    "# ax.bar_label(container)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language Processing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency analysis:\n",
    "\n",
    "Here we count the most frequent tokens in the **whole** corpus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the counter into a Pandas DataFrame with the following function:\n",
    "\n",
    "\"\"\"\n",
    "The tokens make up the index of the DataFrame, while the frequency values are stored in a column named freq. \n",
    "The rows are sorted so that the most frequent words appear at the head.\n",
    "The last parameter of count_words defines a minimum frequency of tokens to be included in the result. \n",
    "Its default is set to 2 to cut down on tokens occurring only once.\n",
    "\"\"\"\n",
    "\n",
    "def count_words(df, column='tokens', process=None, min_freq=2):\n",
    "    # create counter and run through all data\n",
    "    counter = Counter() \n",
    "    \n",
    "    # process tokens and update counter\n",
    "    def update(text):\n",
    "        tokens = text if process is None else process(text, pipeline=pipeline)\n",
    "        counter.update(tokens)\n",
    "    \n",
    "    df[column].map(update)\n",
    "    # transform counter into a DataFrame\n",
    "    freq_df = pd.DataFrame.from_dict(counter, orient='index', columns=['freq']) \n",
    "    freq_df = freq_df.query('freq >= @min_freq')\n",
    "    freq_df.index.name = 'token'\n",
    "    return freq_df.sort_values('freq', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See ten most frequent words in the whole corpus:\n",
    "freq_df = count_words(df) \n",
    "freq_df.head(10)\n",
    "\n",
    "# See all words with their frequencies:\n",
    "# pd.value_counts(np.hstack(df['tokens']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results:\n",
    "ax = freq_df.head(15).plot(kind='barh', width=0.95) \n",
    "ax.invert_yaxis()\n",
    "ax.set(xlabel='Frequency', ylabel='Token', title='Top Words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyword in context (KWIC):\n",
    "\n",
    "KWIC analysis produces a list of text fragments of equal length showing the left and right context of a keyword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The function iteratively collects the keyword contexts by applying the add_kwic function to each document with map. \n",
    "By default, the function returns a list of tuples of the form (left context, keyword, right context). \n",
    "If print_samples is greater than 0, a random sample of the results is printed. \n",
    "Sampling is especially useful with lots of documents because the first entries of the list \n",
    "would otherwise stem from a single or a very small number of documents.\n",
    "\"\"\"\n",
    "\n",
    "def kwic(doc_series, keyword, window=50, print_samples=5):\n",
    "    def add_kwic(text):\n",
    "        kwic_list.extend(keyword_in_context(text, keyword, ignore_case=True, window_width=window))\n",
    "\n",
    "    kwic_list = []\n",
    "    doc_series.map(add_kwic)\n",
    "\n",
    "    if print_samples is None or print_samples == 0:\n",
    "        return kwic_list\n",
    "    else:\n",
    "        k = min(print_samples, len(kwic_list))\n",
    "        print(f'{k} random samples out of {len(kwic_list)} ' +\n",
    "              f\"contexts for '{keyword}':\")\n",
    "        for sample in random.sample(list(kwic_list), k):\n",
    "            print(re.sub(r'[\\n\\t]', ' ', sample[0]) + ' ' +\n",
    "                  sample[1]+' ' +\n",
    "                  re.sub(r'[\\n\\t]', ' ', sample[2]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bellow we apply KWIC for `stk` keyword found from the frequency analysis and print 10 random context appearances.\n",
    "\n",
    "The call is made to the original untokenized & unprocessed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwic(df['text'], 'stk', print_samples=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KWIC for `opholdstilladelse`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwic(df['text'], 'opholdstilladelse', print_samples=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-gram analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**N-grams** are neighboring sequences of items (words, letters, symbols) in a document. \n",
    "\n",
    "Most of the times a probability is assigned to the occurrence of a N-gram (or a word occurring next in a sequence of words). This can help decide which N-grams can be chunked together to form single entities or make predictions for next words (other possible use cases include spelling corrections).  \n",
    "\n",
    "[Here](https://web.stanford.edu/~jurafsky/slp3/slides/LM_4.pdf), are some slides from Stanford which provide an introduction to N-gram models and the math that goes with it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_N_grams(text, ngram=1):\n",
    "    \"\"\"\"custom function to generate n-grams\"\"\"\n",
    "    words = [word for word in text.split(\n",
    "        \" \") if word not in set(STOPWORDS_DANISH)]\n",
    "    # print(\"Sentence after removing stopwords:\", words)\n",
    "    # Use the zip function to help us generate n-grams\n",
    "    temp = zip(*[words[i:] for i in range(0, ngram)])\n",
    "    # Concatentate the tokens into ngrams and return\n",
    "    ans = [' '.join(ngram) for ngram in temp]\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens_joined'] = [' '.join(token) for token in df['tokens']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = defaultdict(int)\n",
    "\n",
    "# Get the count of every bigram in the data set from last processed column:\n",
    "for text in df['tokens_joined']:\n",
    "    for word in generate_N_grams(text, 2):\n",
    "        values[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focus on more frequently occuring words.\n",
    "# Sort in descending order with respect to the column of interest:\n",
    "df_processed = pd.DataFrame(\n",
    "    sorted(values.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "# Ten first values of the first column:\n",
    "c1 = df_processed[0][:10]\n",
    "# Ten first values of the second column:\n",
    "c2 = df_processed[1][:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(16, 4))\n",
    "plt.bar(c1, c2, color='purple',\n",
    "        width=0.4)\n",
    "plt.xlabel(\"Combinations of Words in dataframe\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Top 10 bi-grams in dataframe-BIGRAM ANALYSIS\")\n",
    "# plt.savefig(\"dataset-bigram.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Term Frequency (TF):**\n",
    "\n",
    "The number of times a word appears in a document divded by the total number of words in the document. Every document has its own term frequency.\n",
    "\n",
    "A value close to 1 indicates this term is very important to the document — and primarily composed of it. A low value could mean this term is not very important.\n",
    "\n",
    "**Inverse Data Frequency (IDF):**\n",
    "\n",
    "The log of the number of documents divided by the number of documents that contain the word w. Inverse data frequency determines the weight of rare words across all documents in the corpus.\n",
    "\n",
    "A value close to 0 indicates the term is very common — and not very helpful in differentiating this document from another. A higher value indicates the term is not very common and could be crucial to understanding the theme of this document.\n",
    "\n",
    "The **TF-IDF** is the multiplication of TF by IDF.\n",
    "\n",
    "A value close to 0 indicates the term is not important either in the corpus or the document or both. A larger value indicates the term is unique for the document or the corpus or both. This value works best in relation to other terms in the same document, and other documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the column of interest:\n",
    "docs = df['tokens_joined'].tolist()\n",
    "\n",
    "# Create a vocabulary of words,eliminate stop words if any:\n",
    "\n",
    "cv = CountVectorizer()\n",
    "word_count_vector = cv.fit_transform(docs)\n",
    "\n",
    "# Get shape of resulting vector:\n",
    "word_count_vector.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_vector = cv.fit_transform(docs)\n",
    "\n",
    "# Look at 10 words from our vocabulary:\n",
    "list(cv.vocabulary_.keys())[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer(smooth_idf=True, use_idf=True)\n",
    "tfidf_transformer.fit(word_count_vector)\n",
    "\n",
    "\n",
    "# Peek at the IDF values:\n",
    "tfidf_transformer.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorts the values in the vector while preserving the column index\n",
    "def sort_coo(coo_matrix):\n",
    "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
    "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
    "\n",
    "\n",
    "def extract_top_n_from_vector(feature_names, sorted_items, topn=10):\n",
    "    \"\"\"get the feature names and tf-idf score of top n items\"\"\"\n",
    "\n",
    "    # Use only topn items from vector\n",
    "    sorted_items = sorted_items[:topn]\n",
    "\n",
    "    score_vals = []\n",
    "    feature_vals = []\n",
    "\n",
    "    for idx, score in sorted_items:\n",
    "        fname = feature_names[idx]\n",
    "\n",
    "        # Keep track of feature name and its corresponding score\n",
    "        score_vals.append(round(score, 3))\n",
    "        feature_vals.append(fname)\n",
    "\n",
    "    # Create a tuples of feature,score\n",
    "    # results = zip(feature_vals,score_vals)\n",
    "    results = {}\n",
    "    for idx in range(len(feature_vals)):\n",
    "        results[feature_vals[idx]] = score_vals[idx]\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only need to do this once:\n",
    "feature_names = cv.get_feature_names_out()\n",
    "\n",
    "# Generate tf-idf for all documents in list. docs has 192 documents:\n",
    "tf_idf_vector = tfidf_transformer.transform(cv.transform(docs))\n",
    "\n",
    "results = []\n",
    "for i in range(tf_idf_vector.shape[0]):\n",
    "\n",
    "    # get vector for a single document\n",
    "    curr_vector = tf_idf_vector[i]\n",
    "\n",
    "    # sort the tf-idf vector by descending order of scores\n",
    "    sorted_items = sort_coo(curr_vector.tocoo())   # tocoo() Return a COOrdinate representation of this matrix.\n",
    "\n",
    "    # extract only the top n; n here is 10\n",
    "    keywords = extract_top_n_from_vector(feature_names, sorted_items, 10)\n",
    "\n",
    "    results.append(keywords)\n",
    "\n",
    "df_tfIDF = pd.DataFrame(zip(docs, results), columns=['doc', 'keywords'])\n",
    "# df_tfIDF.shape\n",
    "df_tfIDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary from results list of dictionaries:\n",
    "my_dict = dict(ChainMap(*results))\n",
    "\n",
    "c = Counter(my_dict)\n",
    "\n",
    "# Returns top 20 most common pairs:\n",
    "most_common = c.most_common(20)\n",
    "\n",
    "# For getting the keys from `most_common`:\n",
    "my_keys = [key for key, val in most_common]\n",
    "\n",
    "# Add pretty printer:\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "pp.pprint(most_common)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.bar(range(len(most_common)), [val[1] for val in most_common], align='center')\n",
    "# plt.xticks(range(len(most_common)), [val[0] for val in most_common])\n",
    "# plt.xticks(rotation=70)\n",
    "\n",
    "# sort values in tuple:\n",
    "sorted_most_common = sorted(most_common, key=lambda x: x[1])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "bars = ax.barh([val[0] for val in sorted_most_common], [val[1] for val in sorted_most_common])\n",
    "\n",
    "ax.bar_label(bars)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modelling:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Dirichlet Allocation (LDA):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Probabilistic, generative model which uncovers the topics latent to a dataset by assigning weights to words in a corpus, where each topic will assign different probability weights to each word.\n",
    "\n",
    "For a given corpus, a topic model estimates a topic distribution for each of its documents (i.e., a a distribution of weights over a set of topics), where a topic is itself a distribution of weights over the vocabulary of the corpus. The most weighted words of each topic are syntactically and/or semantically related, given that collection of documents. This means that two distinct topics share the exact same vocabulary, but have different weight distributions.\n",
    "\n",
    "The LDA algorithm first models documents via a mixture model of topics. From these topics, words are then assigned weights based on the probability distribution of these topics. It is this probabilistic assignment over words that allow a user of LDA to say how likely a particular word falls into a topic. Subsequently from the collection of words assigned to a particular topic, are we thus able to gain an insight as to what that topic may actually represent from a lexical point of view.\n",
    "\n",
    "REFs here [1](https://scikit-learn.org/stable/modules/decomposition.html#latentdirichletallocation) and [2](https://arxiv.org/pdf/1405.0099.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to display topics produced by Topic Modelling\n",
    "def display_topics(model, features, num_top_words=5):\n",
    "    for topic, word_vector in enumerate(model.components_):\n",
    "        total = word_vector.sum()\n",
    "        largest = word_vector.argsort()[::-1] # inverts sort order\n",
    "        print(\"\\nTopic %02d\" % topic)\n",
    "        for i in range(0, num_top_words):\n",
    "            print(\" %s (%2.2f)\" % (features[largest[i]], word_vector[largest[i]]*100.0/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_text_vectorizer = CountVectorizer( min_df=2, max_df=0.7)\n",
    "count_text_vectors = count_text_vectorizer.fit_transform(df['tokens_joined'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coherence Score:\n",
    "\n",
    "Compute the coherence score is essentially a measure of how similar the words assigned to each topic are in terms of semantic value. The higher the score, the better.\n",
    "\n",
    "Compute the coherence score for LDA models with 2 to 10 topics and see which number of topics leads to the highest coherence score.\n",
    "\n",
    "Topic coherence in essence measures the human interpretability of a topic model. Traditionally perplexity has been used to evaluate topic models however this does not correlate with human annotations at times. Topic coherence is another way to evaluate topic models with a much higher guarantee on human interpretability. Thus this can be used to compare different topic models among many other use-cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_num_LDA = float('NaN')\n",
    "best_score_LDA = 0\n",
    "\n",
    "# Compute the coherence scores for each number of topics\n",
    "for i in range(2, 11):\n",
    "\n",
    "    # Create LDA model with i topics\n",
    "    LDA_text_model = LatentDirichletAllocation(n_components=i, random_state=42)\n",
    "    W_LDA_text_matrix = LDA_text_model.fit_transform(count_text_vectors)\n",
    "    H_LDA_text_matrix = LDA_text_model.components_\n",
    "\n",
    "    # Obtain the coherence score\n",
    "    coherence_model_LDA = metric_coherence_gensim(measure='c_v', \n",
    "                        top_n=25, \n",
    "                        topic_word_distrib=H_LDA_text_matrix, \n",
    "                        dtm=W_LDA_text_matrix, \n",
    "                        vocab=np.array([x for x in count_text_vectorizer.vocabulary_.keys()]), \n",
    "                        texts=df['tokens'])\n",
    "    coherence_score_LDA = np.around(coherence_model_LDA, 2)\n",
    "    for score in coherence_score_LDA:\n",
    "        if score > best_score_LDA:\n",
    "            best_num_LDA = i\n",
    "            best_score_LDA = score\n",
    "\n",
    "print(f'The coherence score for LDA ({best_score_LDA}) is highest with {best_num_LDA} topics.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the model with the best number of topics and see them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA_model = LatentDirichletAllocation(n_components=best_num_LDA, random_state=42)\n",
    "W_LDA_model_matrix = LDA_model.fit_transform(count_text_vectors)\n",
    "H_LDA_model_matrix = LDA_model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_topics(LDA_model, count_text_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise the topics produced by LDA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "LDA_display = pyLDAvis.sklearn.prepare(LDA_model, count_text_vectors, count_text_vectorizer, sort_topics=False)\n",
    "\n",
    "pyLDAvis.display(LDA_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each bubble in the plot represents a topic. The size of the bubble represents the proportion of cases that contain the topic, with a larger bubble corresponding to a higher proportion. \n",
    "\n",
    "The distance between the bubbles represents the similarity between the topics; the shorter the distance, the more similar the topics.\n",
    "\n",
    "The bars in the bar chart represent the term frequency for each of the words. The blue bars show the overall term frequency in the collection of documents, whereas the red bars show the term frequency for the selected topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMF:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-Negative Matrix Factorization (NMF) is an unsupervised technique so there are no labeling of topics that the model will be trained on. The way it works is that, NMF decomposes (or factorizes) high-dimensional vectors into a lower-dimensional representation. These lower-dimensional vectors are non-negative which also means their coefficients are non-negative.\n",
    "\n",
    "Non-Negative Matrix Factorization is a statistical method that helps us to reduce the dimension of the input corpora or corpora. Internally, it uses the factor analysis method to give comparatively less weightage to the words that are having less coherence\n",
    "\n",
    "REFs here [1](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html#sklearn.decomposition.NMF), [2](https://towardsdatascience.com/topic-modeling-articles-with-nmf-8c6b2a227a45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "best_num_NMF = float('NaN')\n",
    "best_score_NMF = 0\n",
    "\n",
    "# Compute the coherence scores for each number of topics\n",
    "for i in range(2, 11):\n",
    "\n",
    "    # Create NMF model with i topics\n",
    "    NMF_text_model = NMF(n_components=i, random_state=42, max_iter=2000, init='nndsvd')\n",
    "    W_NMF_text_matrix = NMF_text_model.fit_transform(count_text_vectors)\n",
    "    H_NMF_text_matrix = NMF_text_model.components_\n",
    "\n",
    "    # Obtain the coherence score\n",
    "    coherence_model_NMF = metric_coherence_gensim(measure='c_v', \n",
    "                        top_n=25, \n",
    "                        topic_word_distrib=H_NMF_text_matrix, \n",
    "                        dtm=W_NMF_text_matrix, \n",
    "                        vocab=np.array([x for x in count_text_vectorizer.vocabulary_.keys()]), \n",
    "                        texts=df['tokens'])\n",
    "    coherence_score_NMF = np.around(coherence_model_NMF, 2)\n",
    "    for score in coherence_score_NMF:\n",
    "        if score > best_score_NMF:\n",
    "            best_num_NMF = i\n",
    "            best_score_NMF = score\n",
    "\n",
    "print(f'The coherence score for NMF ({best_score_NMF}) is highest with {best_num_NMF} topics.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the model with the best number of topics and see them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NMF_model = NMF(n_components=best_num_NMF, random_state=42, max_iter=2000, init='nndsvd')\n",
    "W_NMF_model_matrix = NMF_model.fit_transform(count_text_vectors)\n",
    "H_NMF_model_matrix = NMF_model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_topics(NMF_model, count_text_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise the topics produced by NMF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "\n",
    "NMF_display = pyLDAvis.sklearn.prepare(NMF_model, count_text_vectors, count_text_vectorizer, sort_topics=False)\n",
    "\n",
    "pyLDAvis.display(NMF_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Semantic Analysis/Indexing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar analysis to NMF but using a different algorithm: Singular Value Decomposition (SVD).\n",
    "\n",
    "Latent semantic indexing (LSI) is an indexing and retrieval method that uses a mathematical technique called singular value decomposition (SVD) to identify patterns in the relationships between the terms and concepts contained in an unstructured collection of text. LSI is based on the principle that words that are used in the same contexts tend to have similar meanings. A key feature of LSI is its ability to extract the conceptual content of a body of text by establishing associations between those terms that occur in similar contexts.\n",
    "\n",
    "The method, also called latent semantic analysis (LSA), uncovers the underlying latent semantic structure in the usage of words in a body of text and how it can be used to extract the meaning of the text in response to user queries, commonly referred to as concept searches. Queries, or concept searches, against a set of documents that have undergone LSI will return results that are conceptually similar in meaning to the search criteria even if the results don’t share a specific word or words with the search criteria.\n",
    "\n",
    "With the rank reduction of the original matrix, what we have is an approximation of the document-term matrix, with a new representation of each document in our corpus. The idea behind LSA is that the original corpus consists of a multitude of terms that in essence have the same meaning. The original matrix can in this sense be viewed as an obscured version of the underlying latent structure we discover when the redundant dimensions are forced together.\n",
    "\n",
    "\"Singlular Value Decomposition (SVD) allows us to reduce the dimensionality of a matrix. Instead of analyzing a full document-term matrix with all documents and all terms, we can reduce the matrix into a lower rank representation. In this, we combine the meaning of terms by compressing the number of columns.\n",
    "\n",
    "To reduce the size of our matrix without losing much quality, we can perform a low-rank approximation on matrix C. This is done by keeping the top k values of Σ and setting the rest to zero, where k is the new rank. Since Σ contains eigenvalues in descending order, and the effect of small eigenvalues on matrix products is small, the zeroing of the lowest values will leave the reduced matrix C' approximate to C. How to retrieve the most optimal k is not an easy task, since we want k top large enough to include as much variety as possible from our original matrix C, but small enough to exclude sampling errors and redundancy. To do this in a formal way, the Frobenius norm can be applied to measure the discrepancy between C and C_k. A less extensive way is just to try out a couple of different k-values and see what generates the best results.\"\n",
    "\n",
    "REFs here [1](https://simonpaarlberg.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "best_num_SVD = float('NaN')\n",
    "best_score_SVD = 0\n",
    "\n",
    "# Compute the coherence scores for each number of topics\n",
    "for i in range(2, 11):\n",
    "\n",
    "    # Create SVD model with i topics\n",
    "    SVD_text_model = TruncatedSVD(n_components=i, random_state=42)\n",
    "    W_SVD_text_matrix = SVD_text_model.fit_transform(count_text_vectors)\n",
    "    H_SVD_text_matrix = SVD_text_model.components_\n",
    "\n",
    "    # Obtain the coherence score\n",
    "    coherence_model_SVD = metric_coherence_gensim(measure='c_v', \n",
    "                        top_n=25, \n",
    "                        topic_word_distrib=H_SVD_text_matrix, \n",
    "                        dtm=W_SVD_text_matrix, \n",
    "                        vocab=np.array([x for x in count_text_vectorizer.vocabulary_.keys()]), \n",
    "                        texts=df['tokens'])\n",
    "    coherence_score_SVD = np.around(coherence_model_SVD, 2)\n",
    "    for score in coherence_score_SVD:\n",
    "        if score > best_score_SVD:\n",
    "            best_num_SVD = i\n",
    "            best_score_SVD = score\n",
    "\n",
    "print(f'The coherence score for SVD ({best_score_SVD}) is highest with {best_num_SVD} topics.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the model with the best number of topics and see them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVD_model = TruncatedSVD(n_components=best_num_SVD, random_state=42)\n",
    "W_SVD_model_matrix = SVD_model.fit_transform(count_text_vectors)\n",
    "H_SVD_model_matrix = SVD_model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_topics(SVD_model, count_text_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise the topics produced by SVD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "\n",
    "# SVD_display = pyLDAvis.sklearn.prepare(SVD_text_model, count_text_vectors, count_text_vectorizer, sort_topics=False)\n",
    "\n",
    "# pyLDAvis.display(SVD_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wordclouds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to produce wordclouds from topic modelling algorithms\n",
    "def wordcloud_topics (model, features, no_top_words=40):\n",
    "    for topics, words in enumerate(model.components_):\n",
    "        size = {}\n",
    "        largest = words.argsort()[::-1] # inverts order\n",
    "        for i in range(0, no_top_words):\n",
    "            size[features[largest[i]]] = abs(words[largest[i]])\n",
    "        wc = WordCloud(background_color=\"white\", max_words=100, width=960, height=540)\n",
    "        wc.generate_from_frequencies(size)\n",
    "        plt.figure(figsize=(12,12))\n",
    "        plt.imshow(wc, interpolation='bilinear')\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WordClouds from the LDA model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud_topics(LDA_model, count_text_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WordClouds from the NMF model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud_topics(NMF_model, count_text_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WordsClouds from the SVD model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud_topics(SVD_model, count_text_vectorizer.get_feature_names_out())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b6672ba510bd43d5df0d34395a84685a825e41d35f5301d8abef98bca1680e82"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
